{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1ab1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# O*NET Career Path Recommender\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"imports finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2927b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work Values loaded: (7866, 7)\n",
      "Interests loaded: (8307, 7)\n",
      "Work Styles loaded: (14064, 12)\n",
      "Occupations loaded: (1016, 3)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "# Load and clean O*NET data files\n",
    "\n",
    "def load_onet_data():\n",
    "    \"\"\"Load O*NET data files and prepare for modeling\"\"\"\n",
    "    base_dir = \"db_29_3_text/db_29_3_text\"\n",
    "    \n",
    "    # Load Work Values\n",
    "    work_values = pd.read_csv(f\"{base_dir}/Work Values.txt\", sep='\\t', encoding='utf-8')\n",
    "    print(f\"Work Values loaded: {work_values.shape}\")\n",
    "    \n",
    "    # Load Interests (RIASEC)\n",
    "    interests = pd.read_csv(f\"{base_dir}/Interests.txt\", sep='\\t', encoding='utf-8')\n",
    "    print(f\"Interests loaded: {interests.shape}\")\n",
    "    \n",
    "    # Load Work Styles\n",
    "    work_styles = pd.read_csv(f\"{base_dir}/Work Styles.txt\", sep='\\t', encoding='utf-8')\n",
    "    print(f\"Work Styles loaded: {work_styles.shape}\")\n",
    "    \n",
    "    # Load Occupation Data\n",
    "    occupations = pd.read_csv(f\"{base_dir}/Occupation Data.txt\", sep='\\t', encoding='utf-8')\n",
    "    print(f\"Occupations loaded: {occupations.shape}\")\n",
    "    \n",
    "    return work_values, interests, work_styles, occupations\n",
    "\n",
    "# Load the data\n",
    "work_values, interests, work_styles, occupations = load_onet_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f1398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions ready!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Feature Engineering\n",
    "# Transform raw data into occupation profiles\n",
    "\n",
    "def process_work_values(work_values):\n",
    "    \"\"\"Process work values data into occupation profiles\"\"\"\n",
    "    # Filter for IM scale (Importance)\n",
    "    wv_im = work_values[work_values['Scale ID'] == 'IM'].copy()\n",
    "    \n",
    "    # Pivot to get occupation profiles\n",
    "    wv_pivot = wv_im.pivot_table(\n",
    "        index='O*NET-SOC Code',\n",
    "        columns='Element Name',\n",
    "        values='Data Value',\n",
    "        aggfunc='mean'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Normalize to 0-1 scale\n",
    "    wv_pivot = wv_pivot / 7.0  # O*NET uses 1-7 scale\n",
    "    return wv_pivot\n",
    "\n",
    "def process_interests(interests):\n",
    "    \"\"\"Process RIASEC interests data\"\"\"\n",
    "    # Filter for OI scale (Occupational Interest)\n",
    "    int_oi = interests[interests['Scale ID'] == 'OI'].copy()\n",
    "    \n",
    "    # Pivot to get occupation profiles\n",
    "    int_pivot = int_oi.pivot_table(\n",
    "        index='O*NET-SOC Code',\n",
    "        columns='Element Name',\n",
    "        values='Data Value',\n",
    "        aggfunc='mean'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Normalize to 0-1 scale\n",
    "    int_pivot = int_pivot / 7.0  # O*NET uses 1-7 scale\n",
    "    return int_pivot\n",
    "\n",
    "def process_work_styles(work_styles):\n",
    "    \"\"\"Process work styles data\"\"\"\n",
    "    # Filter for IM scale (Importance)\n",
    "    ws_im = work_styles[work_styles['Scale ID'] == 'IM'].copy()\n",
    "    \n",
    "    # Pivot to get occupation profiles\n",
    "    ws_pivot = ws_im.pivot_table(\n",
    "        index='O*NET-SOC Code',\n",
    "        columns='Element Name',\n",
    "        values='Data Value',\n",
    "        aggfunc='mean'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Normalize to 0-1 scale\n",
    "    ws_pivot = ws_pivot / 5.0  # O*NET uses 1-5 scale\n",
    "    return ws_pivot\n",
    "\n",
    "print(\"feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9baf9036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete profiles created: (923, 24)\n",
      "Total features: 23\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create Occupation Profiles\n",
    "# Combine all O*NET dimensions into complete occupation profiles\n",
    "\n",
    "def create_occupation_profiles(work_values, interests, work_styles, occupations):\n",
    "    \"\"\"Create complete occupation profiles combining all O*NET dimensions\"\"\"\n",
    "    \n",
    "    # Process each domain\n",
    "    wv_profiles = process_work_values(work_values)\n",
    "    int_profiles = process_interests(interests)\n",
    "    ws_profiles = process_work_styles(work_styles)\n",
    "    \n",
    "    # Get occupation titles\n",
    "    occ_titles = occupations[['O*NET-SOC Code', 'Title']].drop_duplicates()\n",
    "    occ_titles.columns = ['soc', 'title']\n",
    "    occ_titles = occ_titles.set_index('soc')  # Set soc as index\n",
    "    \n",
    "    # Merge all profiles\n",
    "    profiles = wv_profiles.merge(int_profiles, left_index=True, right_index=True, how='outer')\n",
    "    profiles = profiles.merge(ws_profiles, left_index=True, right_index=True, how='outer')\n",
    "    profiles = profiles.fillna(0)\n",
    "    \n",
    "    # Add occupation titles (now both have soc as index)\n",
    "    profiles = profiles.merge(occ_titles, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Reset index to make soc a column\n",
    "    profiles = profiles.reset_index()\n",
    "    profiles = profiles.rename(columns={'index': 'soc'})\n",
    "    \n",
    "    print(f\"Complete profiles created: {profiles.shape}\")\n",
    "    return profiles\n",
    "\n",
    "# Create the profiles\n",
    "profiles = create_occupation_profiles(work_values, interests, work_styles, occupations)\n",
    "print(f\"Total features: {len([col for col in profiles.columns if col not in ['soc', 'title']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b52e309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing non-numeric column: O*NET-SOC Code (type: object)\n",
      "Using 22 numeric features for training\n",
      "Model R² score: 0.9997\n",
      "model done\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train Recommendation Model\n",
    "# Train a model to map user responses to occupation recommendations\n",
    "\n",
    "def train_recommendation_model(profiles):\n",
    "    \"\"\"Train a model to map user responses to occupation recommendations\"\"\"\n",
    "    \n",
    "    # Separate features and target - ONLY numeric columns\n",
    "    feature_cols = [col for col in profiles.columns if col not in ['soc', 'title']]\n",
    "    \n",
    "    # Double-check: ensure all features are numeric\n",
    "    numeric_features = []\n",
    "    for col in feature_cols:\n",
    "        if profiles[col].dtype in ['int64', 'float64']:\n",
    "            numeric_features.append(col)\n",
    "        else:\n",
    "            print(f\"Removing non-numeric column: {col} (type: {profiles[col].dtype})\")\n",
    "    \n",
    "    print(f\"Using {len(numeric_features)} numeric features for training\")\n",
    "    \n",
    "    X = profiles[numeric_features].values\n",
    "    y = profiles[numeric_features].values  # Self-supervised learning\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(f\"Model R² score: {score:.4f}\")\n",
    "    \n",
    "    return model, numeric_features\n",
    "\n",
    "# Train the model\n",
    "model, feature_cols = train_recommendation_model(profiles)\n",
    "print(\"model done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5850d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Questionnaire Scoring System\n",
    "# Convert user responses to O*NET-compatible profiles\n",
    "\n",
    "def score_questionnaire(responses):\n",
    "    \"\"\"Score questionnaire responses to create user profile\"\"\"\n",
    "    \n",
    "    # Extract responses for each section\n",
    "    work_values_resp = responses[:6]      # 6 work value questions\n",
    "    riasec_resp = responses[6:36]        # 30 RIASEC questions (5 per category)\n",
    "    work_styles_resp = responses[36:52]  # 16 work style questions\n",
    "    \n",
    "    # Calculate Work Values scores (normalize 1-5 to 0-1)\n",
    "    wv_scores = {\n",
    "        'Achievement': np.mean([work_values_resp[0], work_values_resp[1]]) / 5.0,\n",
    "        'Working Conditions': np.mean([work_values_resp[2], work_values_resp[3]]) / 5.0,\n",
    "        'Relationships': np.mean([work_values_resp[4], work_values_resp[5]]) / 5.0\n",
    "    }\n",
    "    \n",
    "    # Calculate RIASEC scores (normalize 1-5 to 0-1)\n",
    "    riasec_scores = {}\n",
    "    categories = ['Realistic', 'Investigative', 'Artistic', 'Social', 'Enterprising', 'Conventional']\n",
    "    for i, category in enumerate(categories):\n",
    "        start_idx = 6 + (i * 5)\n",
    "        end_idx = start_idx + 5\n",
    "        riasec_scores[category] = np.mean(riasec_resp[start_idx:end_idx]) / 5.0\n",
    "    \n",
    "    # Calculate Work Styles scores (normalize 1-5 to 0-1)\n",
    "    ws_scores = {\n",
    "        'Achievement/Effort': np.mean(work_styles_resp[0:3]) / 5.0,\n",
    "        'Leadership': work_styles_resp[3] / 5.0,\n",
    "        'Cooperation': np.mean(work_styles_resp[4:6]) / 5.0,\n",
    "        'Stress Tolerance': np.mean(work_styles_resp[6:8]) / 5.0,\n",
    "        'Dependability': np.mean(work_styles_resp[8:10]) / 5.0,\n",
    "        'Adaptability': np.mean(work_styles_resp[10:12]) / 5.0,\n",
    "        'Innovation': work_styles_resp[12] / 5.0,\n",
    "        'Analytical Thinking': work_styles_resp[13] / 5.0,\n",
    "        'Independence': work_styles_resp[14] / 5.0,\n",
    "        'Integrity': work_styles_resp[15] / 5.0\n",
    "    }\n",
    "    \n",
    "    # Combine all scores\n",
    "    user_profile = {**wv_scores, **riasec_scores, **ws_scores}\n",
    "    \n",
    "    return user_profile\n",
    "\n",
    "print(\"questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1020861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career recommendations engine ready!\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Career Recommendations Engine\n",
    "# Generate career recommendations based on user profile\n",
    "\n",
    "def get_career_recommendations(user_profile, model, feature_cols, profiles, top_k=10):\n",
    "    \"\"\"Get top career recommendations based on user profile\"\"\"\n",
    "    \n",
    "    # First, let's see what columns we actually have\n",
    "    print(f\"Available columns in profiles: {profiles.columns.tolist()}\")\n",
    "    print(f\"Looking for columns: soc, title\")\n",
    "    \n",
    "    # Find the actual column names for SOC and title\n",
    "    soc_col = None\n",
    "    title_col = None\n",
    "    \n",
    "    for col in profiles.columns:\n",
    "        if 'soc' in col.lower() or 'code' in col.lower():\n",
    "            soc_col = col\n",
    "        if 'title' in col.lower():\n",
    "            title_col = col\n",
    "    \n",
    "    if soc_col is None or title_col is None:\n",
    "        print(f\"Could not find SOC column: {soc_col}\")\n",
    "        print(f\"Could not find title column: {title_col}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Using SOC column: {soc_col}\")\n",
    "    print(f\"Using title column: {title_col}\")\n",
    "    \n",
    "    # Convert user profile to feature vector\n",
    "    user_vector = np.array([user_profile.get(col, 0) for col in feature_cols])\n",
    "    \n",
    "    # Predict user's ideal occupation profile\n",
    "    predicted_profile = model.predict(user_vector.reshape(1, -1))[0]\n",
    "    \n",
    "    # Calculate similarity with all occupations\n",
    "    occupation_features = profiles[feature_cols].values\n",
    "    similarities = cosine_similarity(occupation_features, predicted_profile.reshape(1, -1)).ravel()\n",
    "    \n",
    "    # Get top matches\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    # Create recommendations dataframe\n",
    "    recommendations = profiles.iloc[top_indices][[soc_col, title_col]].copy()\n",
    "    recommendations['similarity_score'] = similarities[top_indices]\n",
    "    recommendations = recommendations.reset_index(drop=True)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "print(\"Career recommendations engine ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff8f77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in profiles: ['O*NET-SOC Code', 'Artistic', 'Conventional', 'Enterprising', 'Investigative', 'Realistic', 'Social', 'Achievement/Effort', 'Adaptability/Flexibility', 'Analytical Thinking', 'Attention to Detail', 'Concern for Others', 'Cooperation', 'Dependability', 'Independence', 'Initiative', 'Innovation', 'Integrity', 'Leadership', 'Persistence', 'Self-Control', 'Social Orientation', 'Stress Tolerance', 'title']\n",
      "Looking for columns: soc, title\n",
      "Using SOC column: Social Orientation\n",
      "Using title column: title\n",
      "\n",
      "Sample recommendations (neutral profile):\n",
      "   Social Orientation                                              title  \\\n",
      "0                0.65                               Landscape Architects   \n",
      "1                0.63                  Economics Teachers, Postsecondary   \n",
      "2                0.68                    Physics Teachers, Postsecondary   \n",
      "3                0.60                                        Geographers   \n",
      "4                0.64  Atmospheric, Earth, Marine, and Space Sciences...   \n",
      "\n",
      "   similarity_score  \n",
      "0          0.883988  \n",
      "1          0.883862  \n",
      "2          0.882496  \n",
      "3          0.880432  \n",
      "4          0.879539  \n",
      "\n",
      "System test complete! Career recommender is working.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adhi2\\OneDrive\\Documents\\Coding stuff\\OCEAN_TEST_AI\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\adhi2\\OneDrive\\Documents\\Coding stuff\\OCEAN_TEST_AI\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Test System\n",
    "# Test the career recommendation system with sample data\n",
    "\n",
    "# Test with sample responses (all 3s = neutral)\n",
    "sample_responses = [3] * 52  # 52 total questions\n",
    "sample_profile = score_questionnaire(sample_responses)\n",
    "sample_recommendations = get_career_recommendations(sample_profile, model, feature_cols, profiles)\n",
    "\n",
    "print(\"\\nSample recommendations (neutral profile):\")\n",
    "print(sample_recommendations.head())\n",
    "\n",
    "print(\"\\nSystem test complete! Career recommender is working.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ef504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit app code prepared!\n",
      "Next step: Create app.py with the Streamlit interface\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Streamlit App Preparation\n",
    "# Code for the Streamlit interface\n",
    "\n",
    "streamlit_code = '''\n",
    "# Save this as app.py\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the trained model\n",
    "with open('career_recommender_model.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    model = data['model']\n",
    "    feature_cols = data['feature_cols']\n",
    "    profiles = data['profiles']\n",
    "\n",
    "st.title(\"O*NET Career Path Recommender\")\n",
    "st.write(\"Answer the questions below to get personalized career recommendations!\")\n",
    "\n",
    "# Questionnaire sections\n",
    "st.header(\"Work Values Assessment\")\n",
    "st.write(\"Rate how important each is to you in a job (1=Not Important, 5=Extremely Important)\")\n",
    "\n",
    "# Add your 52 questions here as st.slider widgets\n",
    "# Then collect responses and call the recommendation functions\n",
    "\n",
    "st.success(\"Career recommender system ready for Streamlit deployment!\")\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eddc4b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully!\n",
      "📁 File: 'career_recommender_model.pkl'\n",
      "📊 Model size: 58.95 MB\n",
      "\n",
      "✅ Verification successful!\n",
      "📈 Model loaded: <class 'sklearn.multioutput.MultiOutputRegressor'>\n",
      "🔢 Features: 22\n",
      "�� Occupations: 923\n",
      "\n",
      "�� Your Streamlit app is ready to use!\n",
      "Run: streamlit run app.py\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Save Model for Streamlit App\n",
    "# Save the trained model and data that app.py needs\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the complete system\n",
    "save_data = {\n",
    "    'model': model,\n",
    "    'feature_cols': feature_cols,\n",
    "    'profiles': profiles\n",
    "}\n",
    "\n",
    "with open('career_recommender_model.pkl', 'wb') as f:\n",
    "    pickle.dump(save_data, f)\n",
    "\n",
    "print(\"✅ Model saved successfully!\")\n",
    "print(\"📁 File: 'career_recommender_model.pkl'\")\n",
    "print(\"📊 Model size:\", f\"{os.path.getsize('career_recommender_model.pkl') / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Verify the save worked\n",
    "try:\n",
    "    with open('career_recommender_model.pkl', 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    \n",
    "    print(\"\\n✅ Verification successful!\")\n",
    "    print(f\"📈 Model loaded: {type(loaded_data['model'])}\")\n",
    "    print(f\"🔢 Features: {len(loaded_data['feature_cols'])}\")\n",
    "    print(f\"�� Occupations: {len(loaded_data['profiles'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading saved model: {e}\")\n",
    "\n",
    "print(\"\\n�� Your Streamlit app is ready to use!\")\n",
    "print(\"Run: streamlit run app.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
